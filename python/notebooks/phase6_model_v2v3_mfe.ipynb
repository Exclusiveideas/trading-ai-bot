{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 6: V2 Multi-Class & V3 MFE Regression (Retrained)\n\n**Goal:** Predict HOW FAR price moves (MFE) instead of binary win/loss, enabling dynamic take-profit\n\n**Dataset:** ~98K labeled patterns across 5 types, 20 pairs, 4 timeframes with HTF context\n\n**Models:**\n- V2: Multi-class classifier on MFE buckets [<0.5R, 0.5-1R, 1-1.5R, 1.5-2R, 2R+]\n- V3: Regression on continuous MFE value\n- Dynamic TP: Set take-profit at 80% of predicted MFE"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Load Data & Create MFE Bucket Labels\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams[\"figure.dpi\"] = 120\n\nCSV_PATH = \"/Users/muftau/Documents/programming/trading-ai/python/data/training-all.csv\"\n\ndf_raw = pd.read_csv(CSV_PATH, low_memory=False)\ndf_raw = df_raw[df_raw[\"outcome\"].isin([\"win\", \"loss\"])].reset_index(drop=True)\nprint(f\"Dataset: {len(df_raw)} rows\")\n\ndf = df_raw.copy()\n\n# Drop always-null columns\nnull_pct = df.isnull().mean()\nalways_null = null_pct[null_pct > 0.99].index.tolist()\nif always_null:\n    print(f\"Dropping always-null columns: {always_null}\")\n    df = df.drop(columns=always_null)\n\nmetadata_cols = [\n    \"id\", \"pair\", \"start_timestamp\", \"end_timestamp\",\n    \"entry_price\", \"stop_loss\", \"take_profit\", \"notes\",\n    \"nearest_round_number\", \"nearest_support\", \"nearest_resistance\",\n]\nanalysis_only_cols = [\"outcome\", \"r_multiple\", \"bars_to_outcome\", \"max_favorable_excursion\"]\n\n# Encode categoricals\ncategorical_cols = [\"pattern_type\", \"timeframe\", \"trend_state\", \"trading_session\", \"rsi_zone\"]\nhtf_trend_cols = [c for c in df.columns if c.endswith(\"_trend_state\") and c.startswith(\"htf_\")]\ncategorical_cols.extend(htf_trend_cols)\n\nfor col in categorical_cols:\n    if col in df.columns:\n        df[col] = df[col].fillna(\"unknown\")\n\ndf_raw[\"trend_state\"] = df_raw[\"trend_state\"].fillna(\"unknown\")\ndf_raw[\"trading_session\"] = df_raw[\"trading_session\"].fillna(\"unknown\")\n\ndf = pd.get_dummies(df, columns=[c for c in categorical_cols if c in df.columns], dtype=int)\n\ndrop_cols = metadata_cols + analysis_only_cols + [\"quality_rating\"]\nfeature_cols = [c for c in df.columns if c not in drop_cols]\n\nX = df[feature_cols]\nmfe = df_raw[\"max_favorable_excursion\"].values\n\n# --- MFE bucket labels for V2 ---\nbucket_edges = [0, 0.5, 1.0, 1.5, 2.0, np.inf]\nbucket_labels = [\"<0.5R\", \"0.5-1R\", \"1-1.5R\", \"1.5-2R\", \"2R+\"]\nmfe_buckets = pd.cut(mfe, bins=bucket_edges, labels=bucket_labels, right=False)\ny_v2 = mfe_buckets.codes\n\n# --- Binary target for V1b comparison ---\ny_v1 = (df_raw[\"outcome\"] == \"win\").astype(int).values\n\n# --- Continuous MFE target for V3 ---\ny_v3 = mfe\n\nprint(f\"Features: {X.shape[1]}\")\nprint(f\"\\nMFE bucket distribution:\")\nfor i, label in enumerate(bucket_labels):\n    count = (y_v2 == i).sum()\n    print(f\"  {label:8s}: {count:5d} ({count/len(y_v2):.1%})\")\n\n# --- Time-based split ---\nsplit_idx = int(len(X) * 0.8)\nX_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\ny_v1_train, y_v1_test = y_v1[:split_idx], y_v1[split_idx:]\ny_v2_train, y_v2_test = y_v2[:split_idx], y_v2[split_idx:]\ny_v3_train, y_v3_test = y_v3[:split_idx], y_v3[split_idx:]\nmfe_test = mfe[split_idx:]\ndf_test = df_raw.iloc[split_idx:].copy()\n\nprint(f\"\\nTrain: {len(X_train)} | Test: {len(X_test)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: V2 — Multi-Class XGBoost on MFE Buckets\nimport xgboost as xgb\nfrom sklearn.metrics import (\n    accuracy_score, classification_report, confusion_matrix,\n    precision_score, recall_score, f1_score, roc_auc_score,\n)\n\n# Train V1b baseline for comparison\nspw_v1 = (len(y_v1_train) - y_v1_train.sum()) / max(y_v1_train.sum(), 1)\nmodel_v1 = xgb.XGBClassifier(\n    n_estimators=300, max_depth=6, learning_rate=0.05,\n    scale_pos_weight=spw_v1, eval_metric=\"logloss\",\n    random_state=42, enable_categorical=False,\n    subsample=0.8, colsample_bytree=0.8, min_child_weight=5,\n)\nmodel_v1.fit(X_train, y_v1_train)\n\n# Train V2 multi-class\nclass_counts = np.bincount(y_v2_train, minlength=5)\nclass_weights = len(y_v2_train) / (5 * np.maximum(class_counts, 1))\nsample_weights_train = class_weights[y_v2_train]\n\nmodel_v2 = xgb.XGBClassifier(\n    n_estimators=300, max_depth=6, learning_rate=0.05,\n    objective=\"multi:softprob\", num_class=5,\n    eval_metric=\"mlogloss\", random_state=42,\n    enable_categorical=False,\n    subsample=0.8, colsample_bytree=0.8, min_child_weight=5,\n)\nmodel_v2.fit(X_train, y_v2_train, sample_weight=sample_weights_train)\n\ny_v2_pred = model_v2.predict(X_test)\ny_v2_prob = model_v2.predict_proba(X_test)\n\nprint(\"=== V2 Multi-Class Performance ===\")\nprint(f\"Accuracy: {accuracy_score(y_v2_test, y_v2_pred):.3f}\")\nprint(f\"\\n{classification_report(y_v2_test, y_v2_pred, target_names=bucket_labels, zero_division=0)}\")\n\n# Confusion matrix\ncm = confusion_matrix(y_v2_test, y_v2_pred)\nfig, ax = plt.subplots(figsize=(7, 6))\nim = ax.imshow(cm, cmap=\"Blues\")\nax.set_xticks(range(5))\nax.set_yticks(range(5))\nax.set_xticklabels(bucket_labels, rotation=45)\nax.set_yticklabels(bucket_labels)\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"Actual\")\nax.set_title(\"V2 MFE Bucket Confusion Matrix\")\nfor i in range(5):\n    for j in range(5):\n        ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\",\n                color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\", fontsize=12)\nplt.colorbar(im)\nplt.tight_layout()\nplt.show()\n\n# High-MFE detection\npred_high = y_v2_pred >= 3  # predicted 1.5R+\nactual_high = y_v2_test >= 3\nif pred_high.sum() > 0:\n    print(f\"\\nHigh-MFE detection (>= 1.5R):\")\n    print(f\"  Predicted high: {pred_high.sum()} / {len(pred_high)}\")\n    print(f\"  Precision: {(pred_high & actual_high).sum() / max(pred_high.sum(), 1):.3f}\")\n    print(f\"  Recall: {(pred_high & actual_high).sum() / max(actual_high.sum(), 1):.3f}\")\nelse:\n    print(f\"\\nV2 predicted no trades >= 1.5R (actual: {actual_high.sum()})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: V3 — MFE Regression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nmodel_v3 = xgb.XGBRegressor(\n    n_estimators=300, max_depth=6, learning_rate=0.05,\n    objective=\"reg:squarederror\", eval_metric=\"rmse\",\n    random_state=42,\n    subsample=0.8, colsample_bytree=0.8, min_child_weight=5,\n)\nmodel_v3.fit(X_train, y_v3_train)\n\ny_v3_pred = model_v3.predict(X_test)\ny_v3_pred = np.clip(y_v3_pred, 0, None)  # MFE can't be negative\n\nmae = mean_absolute_error(y_v3_test, y_v3_pred)\nrmse = np.sqrt(mean_squared_error(y_v3_test, y_v3_pred))\nr2 = r2_score(y_v3_test, y_v3_pred)\n\nprint(\"=== V3 Regression Performance ===\")\nprint(f\"MAE:  {mae:.3f}R\")\nprint(f\"RMSE: {rmse:.3f}R\")\nprint(f\"R²:   {r2:.3f}\")\nprint(f\"\\nBaseline MAE (predict mean): {np.abs(y_v3_test - y_v3_train.mean()).mean():.3f}R\")\n\n# Scatter: predicted vs actual MFE\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nax = axes[0]\nax.scatter(y_v3_test, y_v3_pred, alpha=0.1, s=10)\nax.plot([0, 4], [0, 4], \"r--\", label=\"Perfect prediction\")\nax.set_xlabel(\"Actual MFE (R)\")\nax.set_ylabel(\"Predicted MFE (R)\")\nax.set_title(\"V3: Predicted vs Actual MFE\")\nax.legend()\n\n# Residual distribution\nax = axes[1]\nresiduals = y_v3_pred - y_v3_test\nax.hist(residuals, bins=50, alpha=0.7)\nax.axvline(x=0, color=\"red\", linestyle=\"--\")\nax.set_xlabel(\"Prediction Error (R)\")\nax.set_ylabel(\"Count\")\nax.set_title(f\"V3 Residuals (MAE={mae:.3f}R)\")\n\nplt.tight_layout()\nplt.show()\n\n# Feature importance for V3\nimp_v3 = model_v3.get_booster().get_score(importance_type=\"gain\")\nimp_df = pd.DataFrame({\"feature\": imp_v3.keys(), \"importance\": imp_v3.values()}).sort_values(\"importance\", ascending=False)\nprint(f\"\\nV3 Top 15 features:\")\nfor _, row in imp_df.head(15).iterrows():\n    print(f\"  {row['feature']:40s} {row['importance']:.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dynamic TP Trading Simulation\n",
    "#\n",
    "# For each test trade, simulate 3 strategies:\n",
    "# A) V1b fixed 2R: take every trade, TP=2R → win=+2R, loss=-1R\n",
    "# B) V2 filtered: only take trades predicted >= 1R bucket, TP=2R\n",
    "# C) V3 dynamic TP: set TP at 80% of predicted MFE, clamped [0.5R, 3R]\n",
    "#    Trade hits dynamic TP if actual MFE >= dynamic TP level\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    actual_mfe = mfe_test[i]\n",
    "    actual_outcome = df_test.iloc[i][\"outcome\"]\n",
    "    entry = df_test.iloc[i][\"entry_price\"]\n",
    "    sl = df_test.iloc[i][\"stop_loss\"]\n",
    "    risk = abs(entry - sl)\n",
    "    \n",
    "    # Strategy A: V1b fixed 2R\n",
    "    pnl_a = 2.0 if actual_outcome == \"win\" else -1.0\n",
    "    \n",
    "    # Strategy B: V2 filtered (only take if predicted bucket >= 1R)\n",
    "    v2_bucket = y_v2_pred[i]\n",
    "    if v2_bucket >= 2:  # predicted 1-1.5R or higher\n",
    "        pnl_b = 2.0 if actual_outcome == \"win\" else -1.0\n",
    "        took_b = True\n",
    "    else:\n",
    "        pnl_b = 0.0\n",
    "        took_b = False\n",
    "    \n",
    "    # Strategy C: V3 dynamic TP\n",
    "    pred_mfe = y_v3_pred[i]\n",
    "    dynamic_tp_r = np.clip(pred_mfe * 0.8, 0.5, 3.0)\n",
    "    # Trade hits dynamic TP if actual MFE reached that level\n",
    "    if actual_mfe >= dynamic_tp_r:\n",
    "        pnl_c = dynamic_tp_r  # won at dynamic TP\n",
    "    else:\n",
    "        pnl_c = -1.0  # stopped out\n",
    "    \n",
    "    results.append({\n",
    "        \"actual_mfe\": actual_mfe,\n",
    "        \"actual_outcome\": actual_outcome,\n",
    "        \"pred_mfe\": pred_mfe,\n",
    "        \"v2_bucket\": v2_bucket,\n",
    "        \"dynamic_tp_r\": dynamic_tp_r,\n",
    "        \"pnl_a\": pnl_a,\n",
    "        \"pnl_b\": pnl_b,\n",
    "        \"took_b\": took_b,\n",
    "        \"pnl_c\": pnl_c,\n",
    "    })\n",
    "\n",
    "sim = pd.DataFrame(results)\n",
    "\n",
    "print(\"=== Trading Simulation (Test Set) ===\")\n",
    "print(f\"\\nStrategy A — V1b Fixed 2R (take all):\")\n",
    "print(f\"  Trades: {len(sim)}\")\n",
    "print(f\"  Wins: {(sim.pnl_a > 0).sum()} ({(sim.pnl_a > 0).mean():.1%})\")\n",
    "print(f\"  Total R: {sim.pnl_a.sum():.1f}R\")\n",
    "print(f\"  Avg R/trade: {sim.pnl_a.mean():.3f}R\")\n",
    "\n",
    "sim_b = sim[sim.took_b]\n",
    "print(f\"\\nStrategy B — V2 Filtered (predicted >= 1R bucket):\")\n",
    "print(f\"  Trades: {len(sim_b)} / {len(sim)} ({len(sim_b)/len(sim):.1%} taken)\")\n",
    "if len(sim_b) > 0:\n",
    "    print(f\"  Wins: {(sim_b.pnl_b > 0).sum()} ({(sim_b.pnl_b > 0).mean():.1%})\")\n",
    "    print(f\"  Total R: {sim_b.pnl_b.sum():.1f}R\")\n",
    "    print(f\"  Avg R/trade: {sim_b.pnl_b.mean():.3f}R\")\n",
    "else:\n",
    "    print(f\"  No trades taken\")\n",
    "\n",
    "print(f\"\\nStrategy C — V3 Dynamic TP (80% of predicted MFE):\")\n",
    "print(f\"  Trades: {len(sim)}\")\n",
    "print(f\"  Wins: {(sim.pnl_c > 0).sum()} ({(sim.pnl_c > 0).mean():.1%})\")\n",
    "print(f\"  Total R: {sim.pnl_c.sum():.1f}R\")\n",
    "print(f\"  Avg R/trade: {sim.pnl_c.mean():.3f}R\")\n",
    "print(f\"  Avg dynamic TP: {sim.dynamic_tp_r.mean():.2f}R\")\n",
    "\n",
    "# Equity curves\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(sim.pnl_a.cumsum().values, label=f\"A: Fixed 2R ({sim.pnl_a.sum():.1f}R)\", linewidth=2)\n",
    "if len(sim_b) > 0:\n",
    "    # Build B equity curve aligned to full index\n",
    "    equity_b = sim.pnl_b.cumsum().values\n",
    "    ax.plot(equity_b, label=f\"B: V2 Filtered ({sim.pnl_b.sum():.1f}R)\", linewidth=2)\n",
    "ax.plot(sim.pnl_c.cumsum().values, label=f\"C: V3 Dynamic TP ({sim.pnl_c.sum():.1f}R)\", linewidth=2)\n",
    "ax.set_xlabel(\"Trade #\")\n",
    "ax.set_ylabel(\"Cumulative R\")\n",
    "ax.set_title(\"Equity Curves: V1b vs V2 vs V3\")\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Comparison Dashboard\n",
    "\n",
    "# V1b metrics\n",
    "y_v1_pred = model_v1.predict(X_test)\n",
    "y_v1_prob = model_v1.predict_proba(X_test)[:, 1]\n",
    "v1_auc = roc_auc_score(y_v1_test, y_v1_prob)\n",
    "\n",
    "# V2: use expected MFE from class probabilities as a continuous score\n",
    "bucket_midpoints = np.array([0.25, 0.75, 1.25, 1.75, 2.5])\n",
    "v2_expected_mfe = (y_v2_prob * bucket_midpoints).sum(axis=1)\n",
    "\n",
    "print(\"=== Model Comparison ===\")\n",
    "print(f\"{'Metric':<25s} {'V1b Binary':>12s} {'V2 Multi-R':>12s} {'V3 Regress':>12s}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Trading metrics from simulation\n",
    "print(f\"{'Total R (test set)':<25s} {sim.pnl_a.sum():>12.1f} {sim.pnl_b.sum():>12.1f} {sim.pnl_c.sum():>12.1f}\")\n",
    "print(f\"{'Avg R/trade':<25s} {sim.pnl_a.mean():>12.3f} {sim.pnl_b.mean() if len(sim_b) > 0 else 0:>12.3f} {sim.pnl_c.mean():>12.3f}\")\n",
    "win_rate_a = (sim.pnl_a > 0).mean()\n",
    "win_rate_b = (sim_b.pnl_b > 0).mean() if len(sim_b) > 0 else 0\n",
    "win_rate_c = (sim.pnl_c > 0).mean()\n",
    "print(f\"{'Win rate':<25s} {win_rate_a:>12.1%} {win_rate_b:>12.1%} {win_rate_c:>12.1%}\")\n",
    "trades_b = len(sim_b) if len(sim_b) > 0 else 0\n",
    "print(f\"{'Trades taken':<25s} {len(sim):>12d} {trades_b:>12d} {len(sim):>12d}\")\n",
    "\n",
    "# Statistical metrics\n",
    "print(f\"{'V1 AUC-ROC':<25s} {v1_auc:>12.3f} {'':>12s} {'':>12s}\")\n",
    "print(f\"{'V2 Accuracy':<25s} {'':>12s} {accuracy_score(y_v2_test, y_v2_pred):>12.3f} {'':>12s}\")\n",
    "print(f\"{'V3 MAE':<25s} {'':>12s} {'':>12s} {mae:>12.3f}\")\n",
    "print(f\"{'V3 R²':<25s} {'':>12s} {'':>12s} {r2:>12.3f}\")\n",
    "\n",
    "# Max drawdown\n",
    "def max_drawdown(pnl_series):\n",
    "    cumulative = pnl_series.cumsum()\n",
    "    running_max = cumulative.cummax()\n",
    "    dd = cumulative - running_max\n",
    "    return dd.min()\n",
    "\n",
    "print(f\"{'Max drawdown':<25s} {max_drawdown(sim.pnl_a):>12.1f}R {max_drawdown(sim.pnl_b):>12.1f}R {max_drawdown(sim.pnl_c):>12.1f}R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Context Analysis — Where does V3 dynamic TP shine?\n\nsim[\"pair\"] = df_test[\"pair\"].values\nsim[\"pattern_type\"] = df_test[\"pattern_type\"].values\nsim[\"trend_state\"] = df_test[\"trend_state\"].values\nsim[\"timeframe\"] = df_test[\"timeframe\"].values\n\nprint(\"=== V3 Dynamic TP Performance by Context ===\")\n\nprint(\"\\n--- By Pair (top 10 by trade count) ---\")\npair_stats = []\nfor pair in sorted(sim[\"pair\"].unique()):\n    sub = sim[sim[\"pair\"] == pair]\n    pair_stats.append((pair, len(sub), sub.pnl_a.sum(), sub.pnl_c.sum()))\npair_stats.sort(key=lambda x: x[1], reverse=True)\nfor pair, n, fixed, dynamic in pair_stats[:10]:\n    print(f\"  {pair:8s}  n={n:5d}  \"\n          f\"fixed_2R={fixed:+.1f}R  \"\n          f\"dynamic={dynamic:+.1f}R  \"\n          f\"delta={dynamic - fixed:+.1f}R\")\n\nprint(\"\\n--- By Pattern ---\")\nfor pt in sorted(sim[\"pattern_type\"].unique()):\n    sub = sim[sim[\"pattern_type\"] == pt]\n    print(f\"  {pt:20s}  n={len(sub):5d}  \"\n          f\"fixed_2R={sub.pnl_a.sum():+.1f}R  \"\n          f\"dynamic={sub.pnl_c.sum():+.1f}R  \"\n          f\"delta={sub.pnl_c.sum() - sub.pnl_a.sum():+.1f}R\")\n\nprint(\"\\n--- By Timeframe ---\")\nfor tf in [\"D\", \"H4\", \"H1\", \"M15\"]:\n    sub = sim[sim[\"timeframe\"] == tf]\n    if len(sub) == 0:\n        continue\n    print(f\"  {tf:20s}  n={len(sub):5d}  \"\n          f\"fixed_2R={sub.pnl_a.sum():+.1f}R  \"\n          f\"dynamic={sub.pnl_c.sum():+.1f}R  \"\n          f\"delta={sub.pnl_c.sum() - sub.pnl_a.sum():+.1f}R\")\n\nprint(\"\\n--- By Trend State ---\")\nfor ts in sorted(sim[\"trend_state\"].unique()):\n    sub = sim[sim[\"trend_state\"] == ts]\n    if len(sub) < 20:\n        continue\n    print(f\"  {ts:25s}  n={len(sub):5d}  \"\n          f\"fixed_2R={sub.pnl_a.sum():+.1f}R  \"\n          f\"dynamic={sub.pnl_c.sum():+.1f}R  \"\n          f\"delta={sub.pnl_c.sum() - sub.pnl_a.sum():+.1f}R\")\n\n# Recovered trades\nrecovered = sim[(sim.pnl_a < 0) & (sim.pnl_c > 0)]\nprint(f\"\\n--- Recovered trades (fixed 2R lost, dynamic TP won) ---\")\nprint(f\"  Count: {len(recovered)} / {(sim.pnl_a < 0).sum()} losses ({len(recovered) / max((sim.pnl_a < 0).sum(), 1):.1%})\")\nif len(recovered) > 0:\n    print(f\"  Avg actual MFE: {recovered.actual_mfe.mean():.2f}R\")\n    print(f\"  Avg dynamic TP: {recovered.dynamic_tp_r.mean():.2f}R\")\n    print(f\"  Total R recovered: {recovered.pnl_c.sum() - recovered.pnl_a.sum():.1f}R\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save Models & Summary\n",
    "import os\n",
    "import json\n",
    "\n",
    "model_dir = \"/Users/muftau/Documents/programming/trading-ai/python/models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model_v2.save_model(os.path.join(model_dir, \"xgb_v2_multiclass.json\"))\n",
    "model_v3.save_model(os.path.join(model_dir, \"xgb_v3_regression.json\"))\n",
    "\n",
    "meta = {\n",
    "    \"features\": feature_cols,\n",
    "    \"n_features\": len(feature_cols),\n",
    "    \"train_size\": len(X_train),\n",
    "    \"test_size\": len(X_test),\n",
    "    \"mfe_bucket_edges\": bucket_edges[:-1] + [999],\n",
    "    \"mfe_bucket_labels\": bucket_labels,\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_dir, \"xgb_v2v3_meta.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Models saved:\")\n",
    "print(f\"  V2: {model_dir}/xgb_v2_multiclass.json\")\n",
    "print(f\"  V3: {model_dir}/xgb_v3_regression.json\")\n",
    "print(f\"  Meta: {model_dir}/xgb_v2v3_meta.json\")\n",
    "\n",
    "print(f\"\\n=== Final Summary ===\")\n",
    "print(f\"Dataset: {len(X)} rows ({len(X_train)} train / {len(X_test)} test)\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"\\nV1b (binary):   AUC={v1_auc:.3f}, Total R={sim.pnl_a.sum():.1f}R\")\n",
    "print(f\"V2  (multi-R):  Acc={accuracy_score(y_v2_test, y_v2_pred):.3f}, Total R={sim.pnl_b.sum():.1f}R\")\n",
    "print(f\"V3  (regress):  MAE={mae:.3f}R, R²={r2:.3f}, Total R={sim.pnl_c.sum():.1f}R\")\n",
    "print(f\"\\nBest strategy by total R on test set: \", end=\"\")\n",
    "totals = {\"V1b Fixed 2R\": sim.pnl_a.sum(), \"V2 Filtered\": sim.pnl_b.sum(), \"V3 Dynamic TP\": sim.pnl_c.sum()}\n",
    "best = max(totals, key=totals.get)\n",
    "print(f\"{best} ({totals[best]:+.1f}R)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}